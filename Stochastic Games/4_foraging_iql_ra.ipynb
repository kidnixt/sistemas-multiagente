{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73812b7",
   "metadata": {},
   "source": [
    "# Foraging - Independent Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dbed19",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32f8dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3a58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from games.foraging import Foraging \n",
    "from agents.independent_q_learning import IQL\n",
    "from agents.random_agent import StochasticRandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a065135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots smaller\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b314e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Information:\n",
      "Rewards:  {'agent_0': 0, 'agent_1': 0}\n",
      "Observations:  {'agent_0': array([2., 1., 2., 5., 5., 2., 6., 5., 1., 3., 6., 1.], dtype=float32), 'agent_1': array([2., 1., 2., 5., 5., 2., 3., 6., 1., 6., 5., 1.], dtype=float32)}\n",
      "Terminations:  {'agent_0': False, 'agent_1': False}\n",
      "Truncations:  {'agent_0': False, 'agent_1': False}\n",
      "Infos:  {'agent_0': {}, 'agent_1': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marrt\\miniconda3\\envs\\pettingzoo_games\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "game = Foraging(config=\"Foraging-8x8-2p-2f-v3\", seed=42)\n",
    "game.reset()\n",
    "\n",
    "#print game information\n",
    "rewards = game.rewards\n",
    "observations = game.observations\n",
    "terminations = game.terminations\n",
    "truncations = game.truncations\n",
    "infos = game.infos\n",
    "print(\"Game Information:\")\n",
    "print(\"Rewards: \", rewards)\n",
    "print(\"Observations: \", observations)\n",
    "print(\"Terminations: \", terminations)\n",
    "\n",
    "print(\"Truncations: \", truncations)\n",
    "print(\"Infos: \", infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39479a6",
   "metadata": {},
   "source": [
    "### Epsilon and Alpha function that will be used in the Q-learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab05de3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Epsilon Function Decay')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def epsilon_func(i: int, min_value=0.05, max_value=1.0, decay_steps=8000):\n",
    "        \"\"\"\n",
    "        Epsilon decay should linearly decay from max_value to min_value in the first decay_steps,\n",
    "        and then stay at min_value for the rest of the training.\n",
    "        \"\"\"\n",
    "        if i < decay_steps:\n",
    "            # Linearly decay epsilon\n",
    "            return max_value - (max_value - min_value) * (i / decay_steps)\n",
    "        else:\n",
    "            # Keep epsilon at min_value after decay_steps\n",
    "            return min_value\n",
    "        \n",
    "def get_epsilon_func(min_value=0.05, max_value=1.0, decay_steps=8000):\n",
    "    \"\"\"\n",
    "    Returns the epsilon function with the specified parameters.\n",
    "    \"\"\"\n",
    "    return partial(epsilon_func, min_value=min_value, max_value=max_value, decay_steps=decay_steps)\n",
    "\n",
    "values = []\n",
    "for i in range(0, 10000):\n",
    "    epsilon = epsilon_func(i)\n",
    "    values.append(epsilon)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(values)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.title('Epsilon Function Decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4470e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha is just 0.1 for all steps\n",
    "def alpha_func(i: int, value=0.1):\n",
    "        return 0.1\n",
    "\n",
    "def get_alpha_func(value =0.1):\n",
    "    \"\"\"\n",
    "    Returns the alpha function with the specified parameters.\n",
    "    \"\"\"\n",
    "    return partial(alpha_func, value=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedd916",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24659837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(game, agents, verbose=False, render=False, training=True):\n",
    "    game.reset()\n",
    "    cum_rewards = dict(map(lambda agent: (agent, 0), game.agents))\n",
    "\n",
    "    if render:\n",
    "        game.render()\n",
    "        time.sleep(3) # Wait for 2 seconds before starting the game\n",
    "\n",
    "    while not game.done():\n",
    "        actions = dict(map(lambda agent: (agent, agents[agent].action()), game.agents))\n",
    "        game.step(actions)\n",
    "\n",
    "        for agent in game.agents:\n",
    "            if training:\n",
    "                # Update the agent only if training is enabled\n",
    "                agents[agent].update()\n",
    "            cum_rewards[agent] += game.reward(agent)\n",
    "\n",
    "        if verbose:\n",
    "            for agent in game.agents:\n",
    "                    print(f\"Agent {agent} reward: {game.reward(agent)}\")\n",
    "                    print(f\"Agent {agent} observe: {game.observe(agent)}\")\n",
    "            \n",
    "        if render:\n",
    "            game.render()\n",
    "            time.sleep(0.15)\n",
    "        \n",
    "    return cum_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3babe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(game, agents, iterations, episodes_per_iteration, verbose=False):\n",
    "    reward_list = {agent: [] for agent in game.agents}\n",
    "    rewards_per_iteration = {agent: [] for agent in game.agents}\n",
    "    for i in range(iterations):\n",
    "        for j in range(episodes_per_iteration):\n",
    "            cum_rewards = run(game, agents, verbose=False, render=False, training=True)\n",
    "            for agent in game.agents:\n",
    "                reward_list[agent].append(cum_rewards[agent])\n",
    "\n",
    "        for agent in game.agents:\n",
    "            rewards_per_iteration[agent].append(np.mean(reward_list[agent][-episodes_per_iteration:]))\n",
    "        if verbose:\n",
    "            # Print the average rewards for each agent after each iteration\n",
    "            print(f\"Iteration {i+1}, Total Episodes {(j+1)* (i+1)}\")\n",
    "            for agent in game.agents:\n",
    "                print(f\"Agent {agent}, Average reward: {rewards_per_iteration[agent][i]}\")\n",
    "    \n",
    "    # return the average rewards for each agent after training\n",
    "    return rewards_per_iteration\n",
    "\n",
    "def plot_rewards(rewards, config):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for agent in rewards:\n",
    "        plt.plot(rewards[agent], label=f\"Agent {agent}\")\n",
    "    plt.title(f\"Rewards for Configuration {config['game']}\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b675ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards_on_multiple_runs(all_rewards, config):\n",
    "    # Convert to 3D array: runs x agents x iterations\n",
    "    all_rewards = np.array(all_rewards)\n",
    "\n",
    "    # Compute mean and std across runs, for each agent and iteration\n",
    "    mean_rewards = np.mean(all_rewards, axis=0)  # shape: agents x iterations\n",
    "    std_rewards = np.std(all_rewards, axis=0)    # shape: agents x iterations\n",
    "\n",
    "    # Plot mean and std for each agent\n",
    "    iterations = np.arange(mean_rewards.shape[1])\n",
    "    for agent_idx, agent in enumerate(game.agents):\n",
    "        plt.plot(iterations, mean_rewards[agent_idx], label=f\"Agent {agent} Mean\")\n",
    "        plt.fill_between(iterations, \n",
    "                        mean_rewards[agent_idx] - std_rewards[agent_idx], \n",
    "                        mean_rewards[agent_idx] + std_rewards[agent_idx], \n",
    "                        alpha=0.2, label=f\"Agent {agent} Std\")\n",
    "\n",
    "    plt.title(f\"Mean and Std Rewards over {config['num_runs']} Runs for {config['game']}\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_sum_all_rewards(all_rewards, config):\n",
    "    # all_rewards shape: (num_runs, num_agents, num_iterations)\n",
    "    # Compute sum of rewards across agents for each run and iteration\n",
    "    sum_rewards_per_run = np.sum(all_rewards, axis=1)  # shape: (num_runs, num_iterations)\n",
    "\n",
    "    # Compute mean and std across runs, for each iteration\n",
    "    mean_sum_rewards = np.mean(sum_rewards_per_run, axis=0)  # shape: (num_iterations,)\n",
    "    std_sum_rewards = np.std(sum_rewards_per_run, axis=0)    # shape: (num_iterations,)\n",
    "\n",
    "    # Plot mean and std of sum of rewards\n",
    "    iterations = np.arange(mean_sum_rewards.shape[0])\n",
    "    plt.plot(iterations, mean_sum_rewards, label=\"Mean Sum of Rewards\")\n",
    "    plt.fill_between(iterations, \n",
    "                    mean_sum_rewards - std_sum_rewards, \n",
    "                    mean_sum_rewards + std_sum_rewards, \n",
    "                    alpha=0.2, label=\"Std Dev\")\n",
    "    plt.axhline(y=1, color='r', linestyle='--', label=\"Target\")\n",
    "    plt.title(f\"Mean and Std of Sum of Rewards over {config['num_runs']} Runs for {config['game']}\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Sum of Rewards\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59668d5",
   "metadata": {},
   "source": [
    "## 5x5 - 2 Players - 2 Food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeee1a0",
   "metadata": {},
   "source": [
    "<img src=\"./attachments/5x5-2p-2f.png\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ff4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"game\": \"Foraging-5x5-2p-2f-v3\",\n",
    "        \"seed\": 3,\n",
    "        \"num_runs\": 5,\n",
    "        \"agent\": {\n",
    "            \"alpha\": get_alpha_func(),\n",
    "            \"epsilon\": get_epsilon_func(),\n",
    "            \"gamma\": 0.9,\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"iterations\": 10,\n",
    "            \"episodes_per_iteration\": 1000,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4092f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marrt\\miniconda3\\envs\\pettingzoo_games\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:275: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "IQL.update() missing 1 required positional argument: 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m game = Foraging(config=config[\u001b[33m\"\u001b[39m\u001b[33mgame\u001b[39m\u001b[33m\"\u001b[39m], seed=config[\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m]) \n\u001b[32m      6\u001b[39m agents = {game.agents[\u001b[32m0\u001b[39m]: IQL(game, game.agents[\u001b[32m0\u001b[39m], alpha_func=config[\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33malpha\u001b[39m\u001b[33m\"\u001b[39m], epsilon_func=config[\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mepsilon\u001b[39m\u001b[33m\"\u001b[39m], \n\u001b[32m      7\u001b[39m                      gamma=config[\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m\"\u001b[39m], seed=i),\n\u001b[32m      8\u001b[39m         game.agents[\u001b[32m1\u001b[39m]: StochasticRandomAgent(game, game.agents[\u001b[32m1\u001b[39m], seed=i)\n\u001b[32m      9\u001b[39m         }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m rewards = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miterations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepisodes_per_iteration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m rewards_matrix = np.array([rewards[agent] \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m game.agents])\n\u001b[32m     12\u001b[39m all_rewards.append(rewards_matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(game, agents, iterations, episodes_per_iteration, verbose)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes_per_iteration):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         cum_rewards = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m game.agents:\n\u001b[32m      8\u001b[39m             reward_list[agent].append(cum_rewards[agent])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(game, agents, verbose, render, training)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m game.agents:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# Update the agent only if training is enabled\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     cum_rewards[agent] += game.reward(agent)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[31mTypeError\u001b[39m: IQL.update() missing 1 required positional argument: 'actions'"
     ]
    }
   ],
   "source": [
    "all_rewards = []\n",
    "\n",
    "for i in range(config[\"num_runs\"]):\n",
    "    print(f\"Run {i+1}/{config['num_runs']}\")\n",
    "    game = Foraging(config=config[\"game\"], seed=config[\"seed\"]) \n",
    "    agents = {game.agents[0]: IQL(game, game.agents[0], alpha_func=config[\"agent\"][\"alpha\"], epsilon_func=config[\"agent\"][\"epsilon\"], \n",
    "                         gamma=config[\"agent\"][\"gamma\"], seed=i),\n",
    "            game.agents[1]: StochasticRandomAgent(game, game.agents[1], seed=i)\n",
    "            }\n",
    "    rewards = train(game, agents, config[\"train\"][\"iterations\"], config[\"train\"][\"episodes_per_iteration\"], verbose=False)\n",
    "    rewards_matrix = np.array([rewards[agent] for agent in game.agents])\n",
    "    all_rewards.append(rewards_matrix)\n",
    "\n",
    "plot_rewards_on_multiple_runs(all_rewards, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sum_all_rewards(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9979b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a single episode on the last trained agents\n",
    "#run(game, agents, verbose=False, render=True, training=False) # Uncomment to run a single episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a8e9f",
   "metadata": {},
   "source": [
    "## 8x8 - 2 Players - 2 Food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f7604",
   "metadata": {},
   "source": [
    "<img src=\"./attachments/8x8-2p-2f.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"game\": \"Foraging-8x8-2p-2f-v3\",\n",
    "        \"seed\": 3,\n",
    "        \"num_runs\": 5,\n",
    "        \"agent\": {\n",
    "            \"alpha\": get_alpha_func(),\n",
    "            \"epsilon\": get_epsilon_func(),\n",
    "            \"gamma\": 0.9\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"iterations\": 10,\n",
    "            \"episodes_per_iteration\": 1000,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "\n",
    "for i in range(config[\"num_runs\"]):\n",
    "    print(f\"Run {i+1}/{config['num_runs']}\")\n",
    "    game = Foraging(config=config[\"game\"], seed=config[\"seed\"]) \n",
    "    agents = {game.agents[0]: IQL(game, game.agents[0], alpha_func=config[\"agent\"][\"alpha\"], epsilon_func=config[\"agent\"][\"epsilon\"], \n",
    "                         gamma=config[\"agent\"][\"gamma\"], seed=i),\n",
    "            game.agents[1]: StochasticRandomAgent(game, game.agents[1], seed=i)\n",
    "            }\n",
    "    rewards = train(game, agents, config[\"train\"][\"iterations\"], config[\"train\"][\"episodes_per_iteration\"], verbose=False)\n",
    "    rewards_matrix = np.array([rewards[agent] for agent in game.agents])\n",
    "    all_rewards.append(rewards_matrix)\n",
    "\n",
    "plot_rewards_on_multiple_runs(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sum_all_rewards(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ce205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agents with render to see how they behave in the environment.\n",
    "# run(game, agents, verbose=False, render=True, training=False) # Uncomment to run a single episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a997ea",
   "metadata": {},
   "source": [
    "## 8x8 - 2 Players - 3 Food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d32d2c",
   "metadata": {},
   "source": [
    "<img src=\"./attachments/8x8-2p-3f.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"game\": \"Foraging-8x8-2p-3f-v3\",\n",
    "        \"seed\": 3,\n",
    "        \"num_runs\": 5,\n",
    "        \"agent\": {\n",
    "            \"alpha\": get_alpha_func(),\n",
    "            \"epsilon\": get_epsilon_func(),\n",
    "            \"gamma\": 0.9\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"iterations\": 30, # This environment requires more iterations to converge\n",
    "            \"episodes_per_iteration\": 1000,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b464bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "\n",
    "for i in range(config[\"num_runs\"]):\n",
    "    print(f\"Run {i+1}/{config['num_runs']}\")\n",
    "    game = Foraging(config=config[\"game\"], seed=config[\"seed\"]) \n",
    "    agents = {game.agents[0]: IQL(game, game.agents[0], alpha_func=config[\"agent\"][\"alpha\"], epsilon_func=config[\"agent\"][\"epsilon\"], \n",
    "                         gamma=config[\"agent\"][\"gamma\"], seed=i),\n",
    "            game.agents[1]: StochasticRandomAgent(game, game.agents[1], seed=i)\n",
    "            }\n",
    "    rewards = train(game, agents, config[\"train\"][\"iterations\"], config[\"train\"][\"episodes_per_iteration\"], verbose=False)\n",
    "    rewards_matrix = np.array([rewards[agent] for agent in game.agents])\n",
    "    all_rewards.append(rewards_matrix)\n",
    "\n",
    "plot_rewards_on_multiple_runs(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sum_all_rewards(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cd568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agents with render to see how they behave in the environment.\n",
    "#run(game, agents, verbose=False, render=True, training=False) # Uncomment to run a single episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83355b57",
   "metadata": {},
   "source": [
    "## 8x8 - 3 Players - 1 Food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf79c0",
   "metadata": {},
   "source": [
    "Aumentamos la cantidad de agentes para ver como se comportan en un ambiente m√°s complejo.\n",
    "\n",
    "<img src=\"./attachments/8x8-3p-1f.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"game\": \"Foraging-8x8-3p-1f-v3\",\n",
    "        \"seed\": 1,\n",
    "        \"num_runs\": 5,\n",
    "        \"agent\": {\n",
    "            \"alpha\": get_alpha_func(),\n",
    "            \"epsilon\": get_epsilon_func(),\n",
    "            \"gamma\": 0.9,\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"iterations\": 10,\n",
    "            \"episodes_per_iteration\": 1000,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "\n",
    "for i in range(config[\"num_runs\"]):\n",
    "    print(f\"Run {i+1}/{config['num_runs']}\")\n",
    "    game = Foraging(config=config[\"game\"], seed=config[\"seed\"]) \n",
    "    agents = agents = {game.agents[0]: IQL(game, game.agents[0], alpha_func=config[\"agent\"][\"alpha\"], epsilon_func=config[\"agent\"][\"epsilon\"], \n",
    "                         gamma=config[\"agent\"][\"gamma\"], seed=i),\n",
    "            game.agents[1]: StochasticRandomAgent(game, game.agents[1], seed=i),\n",
    "            game.agents[2]: StochasticRandomAgent(game, game.agents[2], seed=i)\n",
    "            }\n",
    "    rewards = train(game, agents, config[\"train\"][\"iterations\"], config[\"train\"][\"episodes_per_iteration\"], verbose=False)\n",
    "    rewards_matrix = np.array([rewards[agent] for agent in game.agents])\n",
    "    all_rewards.append(rewards_matrix)\n",
    "\n",
    "plot_rewards_on_multiple_runs(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb448212",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sum_all_rewards(all_rewards, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agents with render to see how they behave in the environment.\n",
    "#run(game, agents, verbose=False, render=True, training=False) # Uncomment to run a single episode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pettingzoo_games",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
